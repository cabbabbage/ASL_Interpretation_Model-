{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "import numpy as np\n",
    "import csv\n",
    "import glob\n",
    "import concurrent.futures\n",
    "import tkinter as tk\n",
    "import mediapipe as mp\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from multiprocessing import Pool\n",
    "from tkinter import filedialog, messagebox, Tk\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from fastdtw import fastdtw\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "\n",
    "# Configurable variables and constants\n",
    "LOOK_AHEAD = 3\n",
    "SENSITIVITY = 0.3\n",
    "MULTIPLIER = 200\n",
    "SEQUENCE_LENGTH = 30\n",
    "NO_SEQUENCES = 30\n",
    "\n",
    "actions = []\n",
    "DATA_PATH = './actions'\n",
    "CSV_FILE = 'action_directory.csv'\n",
    "VIDEOS_PATH = './videos'\n",
    "Model_Name = \"\"\n",
    "\n",
    "# Mediapipe constants\n",
    "NUM_LANDMARKS_HAND = 21 * 3  # Each hand has 21 landmarks with x, y, z coordinates\n",
    "\n",
    "# Mediapipe models and drawing utils\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miscellaneous Functions and Video Editing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hand_landmarks(results):\n",
    "    \"\"\"Extract hand landmarks from Mediapipe results.\"\"\"\n",
    "    left_hand = [[lm.x, lm.y, lm.z] for lm in results.left_hand_landmarks.landmark] if results.left_hand_landmarks else []\n",
    "    right_hand = [[lm.x, lm.y, lm.z] for lm in results.right_hand_landmarks.landmark] if results.right_hand_landmarks else []\n",
    "    return left_hand + right_hand\n",
    "\n",
    "def mediapipe_detection(image, model):\n",
    "    \"\"\"Perform Mediapipe detection on an image.\"\"\"\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert from BGR to RGB\n",
    "    image.flags.writeable = False\n",
    "    results = model.process(image)\n",
    "    image.flags.writeable = True\n",
    "    # Keep image in RGB for drawing\n",
    "    return image, results\n",
    "\n",
    "def extract_keypoints(results):\n",
    "    \"\"\"Extract keypoints from Mediapipe results.\"\"\"\n",
    "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33 * 4)\n",
    "    face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468 * 3)\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21 * 3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21 * 3)\n",
    "    return np.concatenate([pose, face, lh, rh])\n",
    "\n",
    "def draw_styled_landmarks(image, results):\n",
    "    # Draw face connections\n",
    "    mp_drawing.draw_landmarks(\n",
    "        image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION,\n",
    "        mp_drawing.DrawingSpec(color=(80, 110, 10), thickness=1, circle_radius=1),\n",
    "        mp_drawing.DrawingSpec(color=(80, 256, 121), thickness=1, circle_radius=1)\n",
    "    )\n",
    "    # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(\n",
    "        image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "        mp_drawing.DrawingSpec(color=(80, 22, 10), thickness=2, circle_radius=4),\n",
    "        mp_drawing.DrawingSpec(color=(80, 44, 121), thickness=2, circle_radius=2)\n",
    "    )\n",
    "    # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(\n",
    "        image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "        mp_drawing.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=4),\n",
    "        mp_drawing.DrawingSpec(color=(121, 44, 250), thickness=2, circle_radius=2)\n",
    "    )\n",
    "    # Draw right hand connections\n",
    "    mp_drawing.draw_landmarks(\n",
    "        image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "        mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=4),\n",
    "        mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refine MP Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from fastdtw import fastdtw\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "# Constants\n",
    "NUM_LANDMARKS_HAND = 21 * 3  # Each hand has 21 landmarks with x, y, z coordinates\n",
    "\n",
    "def data_refine(action_data_path):\n",
    "    sequences = load_sequences(action_data_path)\n",
    "    \n",
    "    # NEW: Remove frames without hands\n",
    "    print(\"\\nRemoving frames without visible hands...\")\n",
    "    sequences = remove_frames_without_hands(sequences)\n",
    "    \n",
    "    # Prepare reference features\n",
    "    if not sequences:\n",
    "        print(\"No sequences with visible hands found. Exiting.\")\n",
    "        return\n",
    "    reference_sequence = sequences[0]  # Choose a sequence that contains the main pattern\n",
    "    reference_features = extract_features(reference_sequence)\n",
    "    threshold = 0.8  # Adjust this threshold as needed\n",
    "    \n",
    "    # Process sequences to create new data\n",
    "    new_sequences = []\n",
    "    \n",
    "    # First 10 sequences: Isolate pattern and create sequences with slight variations\n",
    "    pattern_sequences = create_pattern_sequences(sequences, reference_features, threshold, num_sequences=10)\n",
    "    new_sequences.extend(pattern_sequences)\n",
    "    \n",
    "    # Next 10 sequences: Trim existing sequences to 30 frames keeping main movement\n",
    "    trimmed_sequences = trim_sequences_to_pattern(sequences, reference_features, threshold, num_sequences=10)\n",
    "    new_sequences.extend(trimmed_sequences)\n",
    "    \n",
    "    # Last 10 sequences: Reduce sequences by removing frames until they are 30 frames long\n",
    "    reduced_sequences = reduce_sequences(sequences, reference_features, threshold, num_sequences=10)\n",
    "    new_sequences.extend(reduced_sequences)\n",
    "    \n",
    "    # Ensure we have exactly 30 sequences\n",
    "    new_sequences = new_sequences[:30]\n",
    "    \n",
    "    # Save new sequences\n",
    "    save_sequences(new_sequences, action_data_path)\n",
    "    \n",
    "    # Interpolation and Filtering\n",
    "    print(\"\\nStarting interpolation and filtering...\")\n",
    "    interpolate_and_filter_sequences(new_sequences, action_data_path)\n",
    "    \n",
    "    # NEW: Ensure all sequences have 30 frames\n",
    "    print(\"\\nEnsuring all sequences have 30 frames...\")\n",
    "    sequences = load_sequences(action_data_path)  # Load sequences again after interpolation and filtering\n",
    "    sequences = pad_sequences_to_length(sequences, length=30)\n",
    "    # Save the padded sequences\n",
    "    save_sequences(sequences, action_data_path)\n",
    "    print(\"All sequences have been padded to 30 frames if necessary.\")\n",
    "\n",
    "def load_sequences(action_data_path):\n",
    "    sequences = []\n",
    "    seq_dirs = [d for d in os.listdir(action_data_path) if os.path.isdir(os.path.join(action_data_path, d))]\n",
    "    seq_dirs = sorted(seq_dirs, key=lambda x: int(x.split('_')[1]))  # Ensure consistent order\n",
    "    for seq_dir in seq_dirs:\n",
    "        seq_path = os.path.join(action_data_path, seq_dir)\n",
    "        frames = []\n",
    "        frame_files = sorted([f for f in os.listdir(seq_path) if f.endswith('.npy')],\n",
    "                             key=lambda x: int(x.split('_')[1].split('.')[0]))\n",
    "        for frame_file in frame_files:\n",
    "            frame_data = np.load(os.path.join(seq_path, frame_file))\n",
    "            frames.append(frame_data)\n",
    "        sequences.append(frames)\n",
    "    return sequences\n",
    "\n",
    "def save_sequences(sequences, action_data_path):\n",
    "    # Remove existing data\n",
    "    shutil.rmtree(action_data_path)\n",
    "    os.makedirs(action_data_path, exist_ok=True)\n",
    "    for i, seq in enumerate(sequences):\n",
    "        seq_dir = os.path.join(action_data_path, f'seq_{i}')\n",
    "        os.makedirs(seq_dir, exist_ok=True)\n",
    "        for j, frame in enumerate(seq):\n",
    "            frame_file = os.path.join(seq_dir, f'frame_{j}.npy')\n",
    "            if frame is not None:\n",
    "                np.save(frame_file, frame)\n",
    "    print(f\"Sequences saved to {action_data_path}\")\n",
    "\n",
    "def create_pattern_sequences(sequences, reference_features, threshold, num_sequences):\n",
    "    new_sequences = []\n",
    "    for _ in range(num_sequences):\n",
    "        seq = select_sequence_with_pattern(sequences, reference_features, threshold)\n",
    "        if seq is None:\n",
    "            break\n",
    "        seq_variation = add_variation(seq)\n",
    "        seq_trimmed = trim_or_extend_sequence(seq_variation, length=30)\n",
    "        new_sequences.append(seq_trimmed)\n",
    "    return new_sequences\n",
    "\n",
    "def trim_sequences_to_pattern(sequences, reference_features, threshold, num_sequences):\n",
    "    new_sequences = []\n",
    "    for _ in range(num_sequences):\n",
    "        seq = select_sequence_with_pattern(sequences, reference_features, threshold)\n",
    "        if seq is None:\n",
    "            break\n",
    "        # NEW: Trim sequence to where hands are visible\n",
    "        seq_trimmed = trim_sequence_to_hands_visible(seq, length=30)\n",
    "        new_sequences.append(seq_trimmed)\n",
    "    return new_sequences\n",
    "\n",
    "def reduce_sequences(sequences, reference_features, threshold, num_sequences):\n",
    "    new_sequences = []\n",
    "    for _ in range(num_sequences):\n",
    "        seq = select_sequence_with_pattern(sequences, reference_features, threshold)\n",
    "        if seq is None:\n",
    "            break\n",
    "        # NEW: Remove frames without hands before reducing\n",
    "        seq = remove_frames_without_hands_in_sequence(seq)\n",
    "        seq_reduced = remove_frames_to_length(seq, length=30)\n",
    "        new_sequences.append(seq_reduced)\n",
    "    return new_sequences\n",
    "\n",
    "def select_sequence_with_pattern(sequences, reference_features, threshold):\n",
    "    for seq in sequences:\n",
    "        if contains_main_pattern(seq, reference_features, threshold):\n",
    "            return seq\n",
    "    return None\n",
    "\n",
    "def contains_main_pattern(sequence, reference_features, threshold):\n",
    "    if not sequence:\n",
    "        return False\n",
    "    sequence_features = extract_features(sequence)\n",
    "    similarity = compute_similarity(sequence_features, reference_features)\n",
    "    return similarity >= threshold\n",
    "\n",
    "def extract_features(sequence):\n",
    "    normalized_sequence = normalize_sequence(sequence)\n",
    "    features = np.array([frame.flatten() for frame in normalized_sequence]).flatten()\n",
    "    return features\n",
    "\n",
    "def normalize_sequence(sequence):\n",
    "    return [normalize_frame(frame) for frame in sequence]\n",
    "\n",
    "def normalize_frame(frame):\n",
    "    # Determine the number of keypoints\n",
    "    num_keypoints = frame.shape[0] // 3\n",
    "    # Reshape the frame into (num_keypoints, 3)\n",
    "    frame_reshaped = frame.reshape((num_keypoints, 3))\n",
    "    # Use the first keypoint as the reference point\n",
    "    reference_point = frame_reshaped[0]  # Adjust index as per your data\n",
    "    # Translate keypoints so that reference point is at the origin\n",
    "    translated_frame = frame_reshaped - reference_point\n",
    "    # Compute distances from the origin for scaling\n",
    "    distances = np.linalg.norm(translated_frame, axis=1)\n",
    "    max_distance = np.max(distances)\n",
    "    # Scale the frame if max_distance is greater than zero\n",
    "    if max_distance > 0:\n",
    "        scaled_frame = translated_frame / max_distance\n",
    "    else:\n",
    "        scaled_frame = translated_frame\n",
    "    # Flatten the scaled frame back to 1D\n",
    "    return scaled_frame.flatten()\n",
    "\n",
    "def compute_similarity(features1, features2):\n",
    "    min_length = min(len(features1), len(features2))\n",
    "    features1 = features1[:min_length].reshape(1, -1)\n",
    "    features2 = features2[:min_length].reshape(1, -1)\n",
    "    similarity = cosine_similarity(features1, features2)[0][0]\n",
    "    return similarity\n",
    "\n",
    "def add_variation(sequence):\n",
    "    return [frame + np.random.normal(0, 0.01, frame.shape) for frame in sequence]\n",
    "\n",
    "def trim_or_extend_sequence(sequence, length):\n",
    "    if len(sequence) > length:\n",
    "        # NEW: Trim frames where hands are not visible\n",
    "        sequence = remove_frames_without_hands_in_sequence(sequence)\n",
    "        if len(sequence) > length:\n",
    "            start = (len(sequence) - length) // 2\n",
    "            return sequence[start:start+length]\n",
    "    # Extend sequence if needed\n",
    "    sequence_extended = sequence.copy()\n",
    "    while len(sequence_extended) < length:\n",
    "        sequence_extended.append(sequence_extended[-1])\n",
    "    return sequence_extended[:length]\n",
    "\n",
    "def trim_sequence_to_main_movement(sequence, reference_features, length):\n",
    "    max_similarity = -1\n",
    "    best_start = 0\n",
    "    # NEW: Remove frames without hands before trimming\n",
    "    sequence = remove_frames_without_hands_in_sequence(sequence)\n",
    "    for start in range(0, len(sequence) - length + 1):\n",
    "        window_sequence = sequence[start:start+length]\n",
    "        window_features = extract_features(window_sequence)\n",
    "        similarity = compute_similarity(window_features, reference_features)\n",
    "        if similarity > max_similarity:\n",
    "            max_similarity = similarity\n",
    "            best_start = start\n",
    "    return sequence[best_start:best_start+length]\n",
    "\n",
    "# NEW FUNCTION: Trim sequence to where hands are visible and adjust length\n",
    "def trim_sequence_to_hands_visible(sequence, length):\n",
    "    # Remove frames without hands\n",
    "    sequence = remove_frames_without_hands_in_sequence(sequence)\n",
    "    # If sequence is longer than desired length, trim equally from both ends\n",
    "    if len(sequence) > length:\n",
    "        extra_frames = len(sequence) - length\n",
    "        start_trim = extra_frames // 2\n",
    "        end_trim = extra_frames - start_trim\n",
    "        sequence = sequence[start_trim: len(sequence) - end_trim]\n",
    "    # If sequence is shorter, pad it\n",
    "    elif len(sequence) < length:\n",
    "        sequence = pad_sequence(sequence, length)\n",
    "    return sequence\n",
    "\n",
    "# Helper function to pad a sequence\n",
    "def pad_sequence(sequence, length):\n",
    "    sequence_extended = sequence.copy()\n",
    "    while len(sequence_extended) < length:\n",
    "        sequence_extended.append(sequence_extended[-1])\n",
    "    return sequence_extended[:length]\n",
    "\n",
    "def remove_frames_to_length(sequence, length):\n",
    "    if len(sequence) <= length:\n",
    "        return sequence\n",
    "    indices = np.linspace(0, len(sequence) - 1, num=length, dtype=int)\n",
    "    return [sequence[i] for i in indices]\n",
    "\n",
    "def interpolate_and_filter_sequences(sequences, action_data_path):\n",
    "    # Interpolate missing keypoints in each sequence\n",
    "    for idx, sequence in enumerate(sequences):\n",
    "        print(f\"Interpolating missing data in sequence {idx}...\")\n",
    "        sequences[idx] = interpolate_sequence(sequence)\n",
    "    \n",
    "    # Find the representative sequence\n",
    "    try:\n",
    "        print(\"\\nFinding representative sequence...\")\n",
    "        flattened_sequences = [np.array(seq).flatten() for seq in sequences if seq]\n",
    "        if not flattened_sequences:\n",
    "            print(\"No sequences available for finding representative sequence.\")\n",
    "            return\n",
    "        X = np.array(flattened_sequences)\n",
    "        kmedoids = KMedoids(n_clusters=1, metric='euclidean', random_state=0).fit(X)\n",
    "        medoid_index = kmedoids.medoid_indices_[0]\n",
    "        representative_sequence = sequences[medoid_index]\n",
    "    except Exception as e:\n",
    "        print(f\"Error finding representative sequence: {e}\")\n",
    "        representative_sequence = sequences[0]\n",
    "    \n",
    "    # Filter each sequence\n",
    "    for idx, seq in enumerate(sequences):\n",
    "        print(f\"\\nFiltering sequence {idx}...\")\n",
    "        try:\n",
    "            if seq:\n",
    "                filtered_seq = filter_sequence(seq, representative_sequence)\n",
    "                sequences[idx] = filtered_seq\n",
    "            else:\n",
    "                print(f\"Sequence {idx} is empty after interpolation. Skipping filtering.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error filtering sequence {idx}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Save the interpolated and filtered sequences\n",
    "    save_sequences(sequences, action_data_path)\n",
    "    print(\"\\nInterpolation and filtering completed.\")\n",
    "\n",
    "def interpolate_sequence(sequence):\n",
    "    try:\n",
    "        lh_start = 33 * 4 + 468 * 3\n",
    "        lh_end = lh_start + NUM_LANDMARKS_HAND\n",
    "        rh_start = lh_end\n",
    "        rh_end = rh_start + NUM_LANDMARKS_HAND\n",
    "\n",
    "        for i in range(1, len(sequence) - 1):\n",
    "            frame = sequence[i]\n",
    "            # Left hand keypoints\n",
    "            for idx in range(lh_start, lh_end, 3):\n",
    "                if np.all(frame[idx:idx + 3] == 0):\n",
    "                    prev_idx, next_idx = find_valid_indices(sequence, i, idx)\n",
    "                    if prev_idx is not None and next_idx is not None:\n",
    "                        interpolate_frames(sequence, prev_idx, next_idx, idx)\n",
    "            # Right hand keypoints\n",
    "            for idx in range(rh_start, rh_end, 3):\n",
    "                if np.all(frame[idx:idx + 3] == 0):\n",
    "                    prev_idx, next_idx = find_valid_indices(sequence, i, idx)\n",
    "                    if prev_idx is not None and next_idx is not None:\n",
    "                        interpolate_frames(sequence, prev_idx, next_idx, idx)\n",
    "        return sequence\n",
    "    except Exception as e:\n",
    "        print(f\"Error during interpolation: {e}\")\n",
    "        return sequence\n",
    "\n",
    "def find_valid_indices(sequence, current_index, idx):\n",
    "    prev_idx = next_idx = None\n",
    "    for j in range(current_index - 1, -1, -1):\n",
    "        if not np.all(sequence[j][idx:idx + 3] == 0):\n",
    "            prev_idx = j\n",
    "            break\n",
    "    for j in range(current_index + 1, len(sequence)):\n",
    "        if not np.all(sequence[j][idx:idx + 3] == 0):\n",
    "            next_idx = j\n",
    "            break\n",
    "    return prev_idx, next_idx\n",
    "\n",
    "def interpolate_frames(sequence, prev_idx, next_idx, idx):\n",
    "    for interp_idx in range(prev_idx + 1, next_idx):\n",
    "        alpha = (interp_idx - prev_idx) / (next_idx - prev_idx)\n",
    "        sequence[interp_idx][idx:idx + 3] = (1 - alpha) * sequence[prev_idx][idx:idx + 3] + alpha * sequence[next_idx][idx:idx + 3]\n",
    "\n",
    "def filter_sequence(seq, representative_sequence):\n",
    "    try:\n",
    "        distance, path = fastdtw(seq, representative_sequence, dist=euclidean)\n",
    "        indices_seq = [index[0] for index in path]\n",
    "        segments = []\n",
    "        start = indices_seq[0]\n",
    "        prev = indices_seq[0]\n",
    "        for idx_seq in indices_seq[1:]:\n",
    "            if idx_seq == prev + 1:\n",
    "                prev = idx_seq\n",
    "            else:\n",
    "                segments.append((start, prev))\n",
    "                start = idx_seq\n",
    "                prev = idx_seq\n",
    "        segments.append((start, prev))\n",
    "        longest_segment = max(segments, key=lambda x: x[1] - x[0])\n",
    "        start_idx, end_idx = longest_segment\n",
    "        filtered_seq = [None if i < start_idx or i > end_idx else seq[i] for i in range(len(seq))]\n",
    "        print(f\"Filtered sequence length: {len([f for f in filtered_seq if f is not None])} frames (non-matching frames removed)\")\n",
    "        return filtered_seq\n",
    "    except Exception as e:\n",
    "        print(f\"Error during filtering: {e}\")\n",
    "        return seq\n",
    "\n",
    "# NEW FUNCTION: Pad sequences to a specified length\n",
    "def pad_sequences_to_length(sequences, length=30):\n",
    "    for idx, seq in enumerate(sequences):\n",
    "        # Remove None frames that may have been introduced\n",
    "        seq = [frame for frame in seq if frame is not None]\n",
    "        sequences[idx] = seq\n",
    "        actual_length = len(seq)\n",
    "        if actual_length < length:\n",
    "            frames_to_add = length - actual_length\n",
    "            if actual_length > 0:\n",
    "                last_frame = seq[-1]\n",
    "                seq.extend([last_frame.copy() for _ in range(frames_to_add)])\n",
    "                print(f\"Sequence {idx} padded with {frames_to_add} frame(s).\")\n",
    "            else:\n",
    "                print(f\"Sequence {idx} is empty. Cannot pad an empty sequence.\")\n",
    "        elif actual_length > length:\n",
    "            # Trim the sequence to the desired length\n",
    "            sequences[idx] = seq[:length]\n",
    "    return sequences\n",
    "\n",
    "# NEW FUNCTION: Remove frames without visible hands from all sequences\n",
    "def remove_frames_without_hands(sequences):\n",
    "    for idx, seq in enumerate(sequences):\n",
    "        sequences[idx] = remove_frames_without_hands_in_sequence(seq)\n",
    "    # Remove empty sequences\n",
    "    sequences = [seq for seq in sequences if seq]\n",
    "    return sequences\n",
    "\n",
    "# NEW FUNCTION: Remove frames without visible hands in a single sequence\n",
    "def remove_frames_without_hands_in_sequence(sequence):\n",
    "    lh_start = 33 * 4 + 468 * 3\n",
    "    lh_end = lh_start + NUM_LANDMARKS_HAND\n",
    "    rh_start = lh_end\n",
    "    rh_end = rh_start + NUM_LANDMARKS_HAND\n",
    "    new_sequence = []\n",
    "    for frame in sequence:\n",
    "        left_hand = frame[lh_start:lh_end]\n",
    "        right_hand = frame[rh_start:rh_end]\n",
    "        # Check if hands are visible (i.e., not all zeros)\n",
    "        if not (np.all(left_hand == 0) and np.all(right_hand == 0)):\n",
    "            new_sequence.append(frame)\n",
    "    return new_sequence\n",
    "\n",
    "# Example usage:\n",
    "# action_data_path = '/path/to/action_data'  # Replace with your actual path\n",
    "# data_refine(action_data_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Movement Data from Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_MP_Extraction(video_path, output_directory):\n",
    "    print(video_path)\n",
    "    print(output_directory)\n",
    "    video_path = \"./videos/\"+video_path\n",
    "    \"\"\"\n",
    "    Extract keypoints from each frame of a video and save as .npy files.\n",
    "\n",
    "    Args:\n",
    "        video_path (str): Path to the input video file.\n",
    "        output_directory (str): Directory to save the output .npy files.\n",
    "        model: Mediapipe model used for detecting keypoints (e.g., Hands, Holistic).\n",
    "    \"\"\"\n",
    "    # Ensure the output directory exists\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = 0\n",
    "    with mp.solutions.holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break  # Exit if video ends\n",
    "\n",
    "            # Perform Mediapipe detection on the frame\n",
    "            image, results = mediapipe_detection(frame, holistic)\n",
    "\n",
    "            # Extract keypoints from the frame\n",
    "            keypoints = extract_keypoints(results)\n",
    "\n",
    "            # Define the output filename based on frame number\n",
    "            output_filename = f\"frame_{frame_count}.npy\"\n",
    "            output_path = os.path.join(output_directory, output_filename)\n",
    "\n",
    "            # Save keypoints as a .npy file\n",
    "            np.save(output_path, keypoints)\n",
    "\n",
    "            frame_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create and save the model\n",
    "def create_and_save_model(DATA_PATH= \"\"):\n",
    "    if DATA_PATH == \"\":\n",
    "        root = Tk()\n",
    "        root.withdraw()  # Hide the root window\n",
    "        DATA_PATH = filedialog.askdirectory(title=\"Select the file in Model Data you want to create\")\n",
    "        \n",
    "    model_name = os.path.basename(DATA_PATH)  # Use the folder name as the model name\n",
    "    actions_csv_path = os.path.join(DATA_PATH, 'actions.csv')\n",
    "\n",
    "    if not os.path.exists(actions_csv_path):\n",
    "        print(f\"Error: actions.csv not found in {DATA_PATH}\")\n",
    "        return\n",
    "\n",
    "    # Load actions from the CSV file (assuming actions are in the second column of the CSV)\n",
    "    actions = []\n",
    "    with open(actions_csv_path, mode='r') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for row in reader:\n",
    "            actions.append(row[1])  # Assuming the action is in the second column\n",
    "\n",
    "    # Create a label map from the loaded actions\n",
    "    label_map = {label: num for num, label in enumerate(actions)}\n",
    "    sequence_length = 30  # Set your sequence length\n",
    "\n",
    "    sequences, labels = [], []\n",
    "    for action in actions:\n",
    "        action_dir = os.path.join(DATA_PATH + \"/actions\", action)\n",
    "        if os.path.exists(action_dir) and os.path.isdir(action_dir):\n",
    "            sequence_dirs = [d for d in os.listdir(action_dir) if d.startswith('seq_')]\n",
    "\n",
    "            action_sequences = []\n",
    "            for sequence_dir in sequence_dirs:\n",
    "                window = []\n",
    "                for frame_num in range(sequence_length):\n",
    "                    npy_path = os.path.join(action_dir, sequence_dir, f\"frame_{frame_num}.npy\")\n",
    "                    if os.path.exists(npy_path):  # Ensure the file exists\n",
    "                        res = np.load(npy_path)\n",
    "                        window.append(res)\n",
    "                    else:\n",
    "                        print(f\"Frame {npy_path} not found, skipping.\")\n",
    "                if len(window) == sequence_length:  # Ensure the full sequence length is met\n",
    "                    action_sequences.append(window)\n",
    "\n",
    "            if len(action_sequences) == 0:\n",
    "                print(f\"No valid sequences found for action: {action}\")\n",
    "                continue\n",
    "\n",
    "            # Add the sequences to the dataset\n",
    "            sequences.extend(action_sequences)\n",
    "            labels.extend([label_map[action]] * len(action_sequences))\n",
    "\n",
    "    # Ensure sequences and labels are not empty\n",
    "    if len(sequences) == 0 or len(labels) == 0:\n",
    "        print(\"No valid sequences or labels found. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # Convert the lists to numpy arrays\n",
    "    X = np.array(sequences)\n",
    "    y = to_categorical(labels).astype(int)\n",
    "\n",
    "    print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
    "\n",
    "    # Split the dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05)\n",
    "\n",
    "    log_dir = os.path.join('Logs')\n",
    "    tb_callback = TensorBoard(log_dir=log_dir)\n",
    "\n",
    "    # Define and compile the model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(sequence_length, X.shape[2])))\n",
    "    model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "    model.add(LSTM(64, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(len(actions), activation='softmax'))\n",
    "    model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "    \n",
    "    model.fit(X_train, y_train, epochs=2000, callbacks=[tb_callback])\n",
    "    model.summary()\n",
    "\n",
    "    # Create the Models directory if it doesn't exist\n",
    "    model_dir = DATA_PATH\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "\n",
    "    # Save the model and its weights\n",
    "    model_path = os.path.join(model_dir, f'{model_name}.h5')\n",
    "    weights_path = os.path.join(model_dir, f'{model_name}_weights.h5')\n",
    "\n",
    "    model.save(model_path)  # Save the entire model\n",
    "    model.save_weights(weights_path)  # Save the model weights separately\n",
    "\n",
    "    print(f\"Model saved at: {model_path}\")\n",
    "    print(f\"Model weights saved at: {weights_path}\")\n",
    "    interpretation(DATA_PATH)\n",
    "\n",
    "# Call the function to create and save the model\n",
    "#create_and_save_model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Live Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import tensorflow as tf\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "import csv\n",
    "\n",
    "def mediapipe_detection(image, model):\n",
    "    \"\"\"Process an image and return the results.\"\"\"\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert color space\n",
    "    image.flags.writeable = False  # Improve performance\n",
    "    results = model.process(image)  # Make prediction\n",
    "    image.flags.writeable = True  # Set back to writeable\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)  # Convert back to BGR\n",
    "    return image, results\n",
    "\n",
    "def draw_styled_landmarks(image, results):\n",
    "    \"\"\"Draw landmarks on the image.\"\"\"\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    # Draw face connections\n",
    "    mp_drawing.draw_landmarks(\n",
    "        image, results.face_landmarks, mp.solutions.holistic.FACEMESH_TESSELATION,\n",
    "        mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "        mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "    )\n",
    "    # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(\n",
    "        image, results.pose_landmarks, mp.solutions.holistic.POSE_CONNECTIONS,\n",
    "        mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "        mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "    )\n",
    "    # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(\n",
    "        image, results.left_hand_landmarks, mp.solutions.holistic.HAND_CONNECTIONS,\n",
    "        mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "        mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "    )\n",
    "    # Draw right hand connections\n",
    "    mp_drawing.draw_landmarks(\n",
    "        image, results.right_hand_landmarks, mp.solutions.holistic.HAND_CONNECTIONS,\n",
    "        mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "        mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "    )\n",
    "\n",
    "def extract_keypoints(results):\n",
    "    \"\"\"Extract keypoints from Mediapipe detection results.\"\"\"\n",
    "    # Extract pose landmarks\n",
    "    pose = np.array(\n",
    "        [[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]\n",
    "    ).flatten() if results.pose_landmarks else np.zeros(33 * 4)\n",
    "    # Extract face landmarks\n",
    "    face = np.array(\n",
    "        [[res.x, res.y, res.z] for res in results.face_landmarks.landmark]\n",
    "    ).flatten() if results.face_landmarks else np.zeros(468 * 3)\n",
    "    # Extract left hand landmarks\n",
    "    left_hand = np.array(\n",
    "        [[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]\n",
    "    ).flatten() if results.left_hand_landmarks else np.zeros(21 * 3)\n",
    "    # Extract right hand landmarks\n",
    "    right_hand = np.array(\n",
    "        [[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]\n",
    "    ).flatten() if results.right_hand_landmarks else np.zeros(21 * 3)\n",
    "    # Concatenate all landmarks\n",
    "    keypoints = np.concatenate([pose, face, left_hand, right_hand])\n",
    "    return keypoints\n",
    "\n",
    "def normalize_frame(frame):\n",
    "    \"\"\"Normalize a single frame of keypoints.\"\"\"\n",
    "    num_keypoints = frame.shape[0] // 3\n",
    "    frame_reshaped = frame.reshape((num_keypoints, 3))\n",
    "    reference_point = frame_reshaped[0]  # Adjust index as per your data\n",
    "    translated_frame = frame_reshaped - reference_point\n",
    "    distances = np.linalg.norm(translated_frame, axis=1)\n",
    "    max_distance = np.max(distances)\n",
    "    if max_distance > 0:\n",
    "        scaled_frame = translated_frame / max_distance\n",
    "    else:\n",
    "        scaled_frame = translated_frame\n",
    "    return scaled_frame.flatten()\n",
    "\n",
    "def hands_are_visible(frame):\n",
    "    \"\"\"Check if hands are visible in the frame.\"\"\"\n",
    "    lh_start = 33 * 4 + 468 * 3\n",
    "    lh_end = lh_start + 21 * 3\n",
    "    rh_start = lh_end\n",
    "    rh_end = rh_start + 21 * 3\n",
    "    left_hand = frame[lh_start:lh_end]\n",
    "    right_hand = frame[rh_start:rh_end]\n",
    "    return not (np.all(left_hand == 0) and np.all(right_hand == 0))\n",
    "\n",
    "def interpretation(DATA_PATH = \"\"):\n",
    "    if DATA_PATH == \"\":\n",
    "        root = tk.Tk()\n",
    "        root.withdraw()  # Hide the main Tkinter window\n",
    "        DATA_PATH = filedialog.askdirectory(title=\"Select directory containing actions.csv and model file (.h5)\")\n",
    "\n",
    "    # Paths for actions.csv and model file\n",
    "    model_name = os.path.basename(DATA_PATH)  # Use the folder name as the model name\n",
    "    actions_csv_path = os.path.join(DATA_PATH, 'actions.csv')\n",
    "\n",
    "    if not os.path.exists(actions_csv_path):\n",
    "        print(f\"Error: actions.csv not found in {DATA_PATH}\")\n",
    "        return\n",
    "\n",
    "    # Load actions from actions.csv\n",
    "    actions = []\n",
    "    with open(actions_csv_path, mode='r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            actions.append(row[1])  # Adjust index if action names are in a different column\n",
    "\n",
    "    actions = np.array(actions)\n",
    "\n",
    "    # Verify actions\n",
    "    print(\"Actions:\", actions)\n",
    "    print(\"Number of actions:\", len(actions))\n",
    "\n",
    "    if len(actions) == 0:\n",
    "        print(\"No actions found in actions.csv.\")\n",
    "        return\n",
    "\n",
    "    # Look for the model file (.h5) in the directory\n",
    "    model_path = None\n",
    "    for file in os.listdir(DATA_PATH):\n",
    "        if file.endswith(\".h5\"):\n",
    "            model_path = os.path.join(DATA_PATH, file)\n",
    "            break\n",
    "\n",
    "    if not model_path:\n",
    "        messagebox.showerror(\"Error\", \"No model file (.h5) found in the selected directory.\")\n",
    "        return\n",
    "\n",
    "    # Load pre-trained model\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    model.summary()\n",
    "\n",
    "    # Initialize variables\n",
    "    sequence = []\n",
    "    sentence = []\n",
    "    predictions = []\n",
    "    threshold = 0.5  # Adjust the threshold as needed\n",
    "    sequence_length = 30  # Ensure this matches your model's expected input length\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    # Set up Mediapipe model\n",
    "    mp_holistic = mp.solutions.holistic\n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, \n",
    "                              min_tracking_confidence=0.5) as holistic:\n",
    "        while cap.isOpened():\n",
    "            # Read video feed\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Make detections\n",
    "            image, results = mediapipe_detection(frame, holistic)\n",
    "            # Draw landmarks\n",
    "            draw_styled_landmarks(image, results)\n",
    "            \n",
    "            # Extract keypoints\n",
    "            keypoints = extract_keypoints(results)\n",
    "            \n",
    "            # Check if hands are visible\n",
    "            if hands_are_visible(keypoints):\n",
    "                # Normalize the keypoints\n",
    "                keypoints_normalized = normalize_frame(keypoints)\n",
    "                # Update the sequence\n",
    "                sequence.append(keypoints_normalized)\n",
    "                sequence = sequence[-sequence_length:]  # Ensure sequence length\n",
    "\n",
    "                if len(sequence) == sequence_length:\n",
    "                    # Make a prediction\n",
    "                    res = model.predict(np.expand_dims(sequence, axis=0))[0]\n",
    "                    predictions.append(np.argmax(res))\n",
    "                    \n",
    "                    # Visualization logic: Only update sentence if prediction is stable\n",
    "                    if np.unique(predictions[-10:])[0] == np.argmax(res):\n",
    "                        if res[np.argmax(res)] > threshold:\n",
    "                            if len(sentence) > 0:\n",
    "                                if actions[np.argmax(res)] != sentence[-1]:\n",
    "                                    sentence.append(actions[np.argmax(res)])\n",
    "                            else:\n",
    "                                sentence.append(actions[np.argmax(res)])\n",
    "\n",
    "                        # Keep the sentence length limited to 5\n",
    "                        if len(sentence) > 5:\n",
    "                            sentence = sentence[-5:]\n",
    "            else:\n",
    "                # Optionally, reset the sequence if hands are not visible\n",
    "                sequence = []\n",
    "                predictions = []\n",
    "\n",
    "            # Display predictions on the screen\n",
    "            cv2.rectangle(image, (0, 0), (640, 40), (245, 117, 16), -1)\n",
    "            cv2.putText(image, ' '.join(sentence), (3, 30), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Show the frame\n",
    "            cv2.imshow('Realtime LSTM Sign Language Detection', image)\n",
    "\n",
    "            # Break the loop gracefully\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "    # Release video capture and close windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GUI Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28288.mp4\n",
      "Model_data/test_8\\actions\\human\\seq_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Cal\\miniconda3\\envs\\cs456\\lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28291.mp4\n",
      "Model_data/test_8\\actions\\human\\seq_1\n",
      "28292.mp4\n",
      "Model_data/test_8\\actions\\human\\seq_2\n",
      "28296.mp4\n",
      "Model_data/test_8\\actions\\human\\seq_3\n",
      "\n",
      "Removing frames without visible hands...\n",
      "Sequences saved to Model_data/test_8\\actions\\human\n",
      "\n",
      "Starting interpolation and filtering...\n",
      "Interpolating missing data in sequence 0...\n",
      "Interpolating missing data in sequence 1...\n",
      "Interpolating missing data in sequence 2...\n",
      "Interpolating missing data in sequence 3...\n",
      "Interpolating missing data in sequence 4...\n",
      "Interpolating missing data in sequence 5...\n",
      "Interpolating missing data in sequence 6...\n",
      "Interpolating missing data in sequence 7...\n",
      "Interpolating missing data in sequence 8...\n",
      "Interpolating missing data in sequence 9...\n",
      "Interpolating missing data in sequence 10...\n",
      "Interpolating missing data in sequence 11...\n",
      "Interpolating missing data in sequence 12...\n",
      "Interpolating missing data in sequence 13...\n",
      "Interpolating missing data in sequence 14...\n",
      "Interpolating missing data in sequence 15...\n",
      "Interpolating missing data in sequence 16...\n",
      "Interpolating missing data in sequence 17...\n",
      "Interpolating missing data in sequence 18...\n",
      "Interpolating missing data in sequence 19...\n",
      "Interpolating missing data in sequence 20...\n",
      "Interpolating missing data in sequence 21...\n",
      "Interpolating missing data in sequence 22...\n",
      "Interpolating missing data in sequence 23...\n",
      "Interpolating missing data in sequence 24...\n",
      "Interpolating missing data in sequence 25...\n",
      "Interpolating missing data in sequence 26...\n",
      "Interpolating missing data in sequence 27...\n",
      "Interpolating missing data in sequence 28...\n",
      "Interpolating missing data in sequence 29...\n",
      "\n",
      "Finding representative sequence...\n",
      "Error finding representative sequence: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (30,) + inhomogeneous part.\n",
      "\n",
      "Filtering sequence 0...\n",
      "Filtered sequence length: 17 frames (non-matching frames removed)\n",
      "\n",
      "Filtering sequence 1...\n",
      "Filtered sequence length: 30 frames (non-matching frames removed)\n",
      "\n",
      "Filtering sequence 2...\n",
      "Filtered sequence length: 30 frames (non-matching frames removed)\n",
      "\n",
      "Filtering sequence 3...\n",
      "Filtered sequence length: 30 frames (non-matching frames removed)\n",
      "\n",
      "Filtering sequence 4...\n",
      "Filtered sequence length: 30 frames (non-matching frames removed)\n",
      "\n",
      "Filtering sequence 5...\n",
      "Filtered sequence length: 30 frames (non-matching frames removed)\n",
      "\n",
      "Filtering sequence 6...\n",
      "Filtered sequence length: 30 frames (non-matching frames removed)\n",
      "\n",
      "Filtering sequence 7...\n",
      "Filtered sequence length: 30 frames (non-matching frames removed)\n",
      "\n",
      "Filtering sequence 8...\n",
      "Filtered sequence length: 30 frames (non-matching frames removed)\n",
      "\n",
      "Filtering sequence 9...\n",
      "Filtered sequence length: 30 frames (non-matching frames removed)\n",
      "\n",
      "Filtering sequence 10...\n",
      "Filtered sequence length: 30 frames (non-matching frames removed)\n",
      "\n",
      "Filtering sequence 11...\n",
      "Filtered sequence length: 30 frames (non-matching frames removed)\n",
      "\n",
      "Filtering sequence 12...\n",
      "Filtered sequence length: 30 frames (non-matching frames removed)\n",
      "\n",
      "Filtering sequence 13...\n",
      "Filtered sequence length: 30 frames (non-matching frames removed)\n",
      "\n",
      "Filtering sequence 14...\n",
      "Filtered sequence length: 30 frames (non-matching frames removed)\n",
      "\n",
      "Filtering sequence 15...\n",
      "Filtered sequence length: 30 frames (non-matching frames removed)\n",
      "\n",
      "Filtering sequence 16...\n",
      "Filtered sequence length: 30 frames (non-matching frames removed)\n",
      "\n",
      "Filtering sequence 17...\n",
      "Filtered sequence length: 30 frames (non-matching frames removed)\n",
      "\n",
      "Filtering sequence 18...\n",
      "Filtered sequence length: 30 frames (non-matching frames removed)\n",
      "\n",
      "Filtering sequence 19...\n",
      "Filtered sequence length: 30 frames (non-matching frames removed)\n",
      "\n",
      "Filtering sequence 20...\n",
      "Filtered sequence length: 14 frames (non-matching frames removed)\n",
      "\n",
      "Filtering sequence 21...\n",
      "Filtered sequence length: 14 frames (non-matching frames removed)\n",
      "\n",
      "Filtering sequence 22...\n",
      "Filtered sequence length: 14 frames (non-matching frames removed)\n",
      "\n",
      "Filtering sequence 23...\n",
      "Filtered sequence length: 14 frames (non-matching frames removed)\n",
      "\n",
      "Filtering sequence 24...\n",
      "Filtered sequence length: 14 frames (non-matching frames removed)\n",
      "\n",
      "Filtering sequence 25...\n",
      "Filtered sequence length: 14 frames (non-matching frames removed)\n",
      "\n",
      "Filtering sequence 26...\n",
      "Filtered sequence length: 14 frames (non-matching frames removed)\n",
      "\n",
      "Filtering sequence 27...\n",
      "Filtered sequence length: 14 frames (non-matching frames removed)\n",
      "\n",
      "Filtering sequence 28...\n",
      "Filtered sequence length: 14 frames (non-matching frames removed)\n",
      "\n",
      "Filtering sequence 29...\n",
      "Filtered sequence length: 14 frames (non-matching frames removed)\n",
      "Sequences saved to Model_data/test_8\\actions\\human\n",
      "\n",
      "Interpolation and filtering completed.\n",
      "\n",
      "Ensuring all sequences have 30 frames...\n",
      "Sequence 0 padded with 13 frame(s).\n",
      "Sequence 20 padded with 16 frame(s).\n",
      "Sequence 21 padded with 16 frame(s).\n",
      "Sequence 22 padded with 16 frame(s).\n",
      "Sequence 23 padded with 16 frame(s).\n",
      "Sequence 24 padded with 16 frame(s).\n",
      "Sequence 25 padded with 16 frame(s).\n",
      "Sequence 26 padded with 16 frame(s).\n",
      "Sequence 27 padded with 16 frame(s).\n",
      "Sequence 28 padded with 16 frame(s).\n",
      "Sequence 29 padded with 16 frame(s).\n",
      "Sequences saved to Model_data/test_8\\actions\\human\n",
      "All sequences have been padded to 30 frames if necessary.\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox, filedialog\n",
    "import os\n",
    "import random\n",
    "import csv\n",
    "\n",
    "# Global variables\n",
    "new_csv_path = \"\"\n",
    "is_random = False\n",
    "num_actions = 0\n",
    "specific_action_lines = []\n",
    "actions = []\n",
    "open_window = None  # Keep track of the currently open window\n",
    "\n",
    "# Load actions from the CSV file\n",
    "def load_actions():\n",
    "    global actions\n",
    "    global CSV_FILE\n",
    "    if not os.path.exists(CSV_FILE):\n",
    "        print(f\"CSV_FILE '{CSV_FILE}' does not exist.\")\n",
    "        return\n",
    "    with open(CSV_FILE, mode='r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        actions = [row for row in reader]\n",
    "\n",
    "# Close the current window if one is open\n",
    "def close_current_window():\n",
    "    global open_window\n",
    "    if open_window is not None:\n",
    "        open_window.destroy()\n",
    "        open_window = None\n",
    "\n",
    "# First window to create a new model directory\n",
    "def create_new_model():\n",
    "    def on_create_model():\n",
    "        model_name = \"Model_data/\" + model_name_entry.get()\n",
    "        global DATA_PATH\n",
    "        DATA_PATH = model_name\n",
    "\n",
    "        if not model_name_entry.get():\n",
    "            messagebox.showerror(\"Error\", \"Model name cannot be empty!\")\n",
    "            return\n",
    "        model_dir = os.path.join(os.getcwd(), model_name)\n",
    "\n",
    "        if os.path.exists(model_dir):\n",
    "            messagebox.showerror(\"Error\", \"Directory already exists!\")\n",
    "        else:\n",
    "            os.makedirs(model_dir)\n",
    "            messagebox.showinfo(\"Success\", f\"Directory '{model_name}' created!\")\n",
    "            open_create_from_window(model_name, model_window)  # Pass model_window to close later\n",
    "\n",
    "    # Close the current window before opening a new one\n",
    "    close_current_window()\n",
    "\n",
    "    # GUI for model creation\n",
    "    model_window = tk.Toplevel(root)\n",
    "    model_window.title(\"Create New Model\")\n",
    "    model_window.geometry(\"400x200\")\n",
    "    \n",
    "    # Track the newly opened window\n",
    "    global open_window\n",
    "    open_window = model_window\n",
    "\n",
    "    model_name_label = tk.Label(model_window, text=\"Enter new model name:\")\n",
    "    model_name_label.pack(pady=10)\n",
    "\n",
    "    model_name_entry = tk.Entry(model_window)\n",
    "    model_name_entry.pack(pady=10)\n",
    "\n",
    "    create_model_button = tk.Button(model_window, text=\"Create Model\", command=on_create_model)\n",
    "    create_model_button.pack(pady=10)\n",
    "\n",
    "# New window \"Create From...\"\n",
    "def open_create_from_window(model_name, previous_window):\n",
    "    def open_csv_creation():\n",
    "        previous_window.destroy()  # Close previous window\n",
    "        create_action_selection_window(model_name, create_from_window)\n",
    "\n",
    "    def open_existing_videos():\n",
    "        previous_window.destroy()  # Close previous window\n",
    "        from_videos()  # Open the from_videos window\n",
    "\n",
    "    def open_existing_mp_data():\n",
    "        previous_window.destroy()  # Close previous window\n",
    "        from_mp_data()  # Handle the existing MP Data option\n",
    "\n",
    "    # Close the current window before opening a new one\n",
    "    close_current_window()\n",
    "\n",
    "    create_from_window = tk.Toplevel(root)\n",
    "    create_from_window.title(\"Create From...\")\n",
    "    create_from_window.geometry(\"400x300\")\n",
    "\n",
    "    # Track the newly opened window\n",
    "    global open_window\n",
    "    open_window = create_from_window\n",
    "\n",
    "    # Label\n",
    "    create_from_label = tk.Label(create_from_window, text=\"How would you like to create new model?\")\n",
    "    create_from_label.pack(pady=10)\n",
    "\n",
    "    # Fresh Button\n",
    "    fresh_button = tk.Button(create_from_window, text=\"Fresh\", command=open_csv_creation)\n",
    "    fresh_button.pack(pady=10)\n",
    "    tk.Label(create_from_window, text=\"Create model by selecting actions, preprocess and process videos, extract MP data, test, train, and save model.\").pack(pady=5)\n",
    "\n",
    "    # Existing Videos Button\n",
    "    existing_videos_button = tk.Button(create_from_window, text=\"Existing MP Data\", command=open_existing_videos)\n",
    "    existing_videos_button.pack(pady=10)\n",
    "    tk.Label(create_from_window, text=\"Create models from existing MP data, test, train, and save model.\").pack(pady=5)\n",
    "\n",
    "\n",
    "\n",
    "# Function to process videos\n",
    "def from_videos(processed=True):\n",
    "    def begin_processing_and_extraction():\n",
    "        model_action_path = os.path.join(DATA_PATH, \"actions\")\n",
    "        os.makedirs(model_action_path, exist_ok=True)\n",
    "\n",
    "        if not processed:\n",
    "            # Process actions based on CSV_FILE\n",
    "            for line in actions:\n",
    "                action_name_dir = os.path.join(model_action_path, line[1])\n",
    "                os.makedirs(action_name_dir, exist_ok=True)\n",
    "                i = 0\n",
    "                for element in line[2:]:  # Skipping pos 0 and pos 1 elements\n",
    "                    mp_path = os.path.join(action_name_dir, \"seq_\"+str(i))\n",
    "                    full_MP_Extraction(element, mp_path)\n",
    "                    i += 1\n",
    "                data_refine(action_name_dir)\n",
    "            messagebox.showinfo(\"Success\", \"Processing and extraction complete!\")\n",
    "        else:\n",
    "            # Open file explorer for user to select directory\n",
    "            selected_path = filedialog.askdirectory()\n",
    "            if selected_path:\n",
    "                actions_dir = os.path.join(selected_path, 'actions')\n",
    "                actions_csv = os.path.join(selected_path, 'actions.csv')\n",
    "                if os.path.exists(actions_dir) and os.path.exists(actions_csv):\n",
    "                    # Copy the 'actions' directory and 'actions.csv' into DATA_PATH\n",
    "                    target_actions_dir = os.path.join(DATA_PATH, 'actions')\n",
    "                    target_actions_csv = os.path.join(DATA_PATH, 'actions.csv')\n",
    "                    os.makedirs(target_actions_dir, exist_ok=True)\n",
    "\n",
    "                    # Copy actions directory and actions.csv\n",
    "                    os.system(f'cp -r \"{actions_dir}\" \"{target_actions_dir}\"')\n",
    "                    os.system(f'cp \"{actions_csv}\" \"{target_actions_csv}\"')\n",
    "                    \n",
    "                    messagebox.showinfo(\"Success\", \"Preprocessed data has been copied!\")\n",
    "                else:\n",
    "                    messagebox.showerror(\"Error\", \"Selected directory must contain 'actions' and 'actions.csv'.\")\n",
    "            else:\n",
    "                messagebox.showerror(\"Error\", \"No directory selected.\")\n",
    "        create_and_save_model(DATA_PATH)\n",
    "\n",
    "    # Close the current window before opening a new one\n",
    "    close_current_window()\n",
    "\n",
    "    video_window = tk.Toplevel(root)\n",
    "    video_window.title(\"From Videos\")\n",
    "    video_window.geometry(\"400x300\")\n",
    "\n",
    "    # Track the newly opened window\n",
    "    global open_window\n",
    "    open_window = video_window\n",
    "\n",
    "    # Instruction label\n",
    "    if not processed:\n",
    "        instruction_label = tk.Label(video_window, text=\"Processing unprocessed data from CSV.\")\n",
    "    else:\n",
    "        instruction_label = tk.Label(video_window, text=\"Select preprocessed data directory.\")\n",
    "    instruction_label.pack(pady=10)\n",
    "\n",
    "    # Add a button to start processing\n",
    "    if processed:\n",
    "        select_data_button = tk.Button(video_window, text=\"Select Data Directory\", command=begin_processing_and_extraction)\n",
    "        select_data_button.pack(pady=20)\n",
    "    else:\n",
    "        process_button = tk.Button(video_window, text=\"Begin Processing and Extraction\", command=begin_processing_and_extraction)\n",
    "        process_button.pack(pady=20)\n",
    "\n",
    "# Process MP data (placeholder)\n",
    "def from_mp_data():\n",
    "    close_current_window()\n",
    "    mp_window = tk.Toplevel(root)\n",
    "    mp_window.title(\"From MP Data\")\n",
    "    mp_window.geometry(\"400x300\")\n",
    "\n",
    "    global open_window\n",
    "    open_window = mp_window\n",
    "\n",
    "    tk.Label(mp_window, text=\"This is the MP Data window.\").pack()\n",
    "\n",
    "# Second window to select actions for creating CSV\n",
    "def create_action_selection_window(model_name, previous_window):\n",
    "    def on_checkbox_selected(selected_var):\n",
    "        # Deselect other checkboxes when one is selected\n",
    "        if selected_var == all_actions_var:\n",
    "            number_of_actions_var.set(0)\n",
    "            specify_actions_var.set(0)\n",
    "            number_of_actions_frame.pack_forget()\n",
    "            specify_actions_frame.pack_forget()\n",
    "        elif selected_var == number_of_actions_var:\n",
    "            all_actions_var.set(0)\n",
    "            specify_actions_var.set(0)\n",
    "            number_of_actions_frame.pack(pady=10)\n",
    "            specify_actions_frame.pack_forget()\n",
    "        elif selected_var == specify_actions_var:\n",
    "            all_actions_var.set(0)\n",
    "            number_of_actions_var.set(0)\n",
    "            number_of_actions_frame.pack_forget()\n",
    "            specify_actions_frame.pack(pady=10)\n",
    "\n",
    "    def on_create_model_csv():\n",
    "        global is_random\n",
    "        new_csv_path = os.path.join(os.getcwd(), model_name, \"actions.csv\")\n",
    "        with open(new_csv_path, 'w', newline='') as new_csv:\n",
    "            writer = csv.writer(new_csv)\n",
    "            if all_actions_var.get():\n",
    "                # Copy all actions from the CSV file\n",
    "                for row in actions:\n",
    "                    writer.writerow(row)\n",
    "            elif number_of_actions_var.get():\n",
    "                # Select a number of actions\n",
    "                num = int(num_actions_entry.get())\n",
    "                is_random = random_checkbox_var.get()\n",
    "                if num > len(actions):\n",
    "                    messagebox.showerror(\"Error\", f\"Number exceeds total actions ({len(actions)}).\")\n",
    "                    return\n",
    "                selected_actions = random.sample(actions, num) if is_random else actions[:num]\n",
    "                for row in selected_actions:\n",
    "                    writer.writerow(row)\n",
    "            elif specify_actions_var.get():\n",
    "                # Write specific actions to new CSV\n",
    "                if not specific_action_lines:\n",
    "                    messagebox.showerror(\"Error\", \"No actions selected.\")\n",
    "                    return\n",
    "                for line in specific_action_lines:\n",
    "                    writer.writerow(line)\n",
    "            else:\n",
    "                messagebox.showerror(\"Error\", \"No option selected.\")\n",
    "                return\n",
    "\n",
    "        messagebox.showinfo(\"Success\", f\"CSV created at: {new_csv_path}\")\n",
    "        previous_window.destroy()  # Close the CSV selection window\n",
    "        global CSV_FILE\n",
    "        CSV_FILE = new_csv_path\n",
    "        load_actions()\n",
    "        from_videos(False)  # Call `from_videos` after creating CSV\n",
    "\n",
    "    # Close the current window before opening a new one\n",
    "    close_current_window()\n",
    "\n",
    "    action_window = tk.Toplevel(root)\n",
    "    previous_window.destroy()  # Close the \"Create From\" window\n",
    "    action_window.title(\"Select Actions\")\n",
    "    action_window.geometry(\"600x600\")\n",
    "\n",
    "    global open_window\n",
    "    open_window = action_window\n",
    "\n",
    "    # --- Action Selection Checkboxes ---\n",
    "    all_actions_var = tk.IntVar(value=1)\n",
    "    number_of_actions_var = tk.IntVar(value=0)\n",
    "    specify_actions_var = tk.IntVar(value=0)\n",
    "\n",
    "    all_actions_checkbox = tk.Checkbutton(action_window, text=\"All Actions\", variable=all_actions_var, command=lambda: on_checkbox_selected(all_actions_var))\n",
    "    all_actions_checkbox.pack(anchor='w')\n",
    "\n",
    "    number_of_actions_checkbox = tk.Checkbutton(action_window, text=\"# of Actions\", variable=number_of_actions_var, command=lambda: on_checkbox_selected(number_of_actions_var))\n",
    "    number_of_actions_checkbox.pack(anchor='w')\n",
    "\n",
    "    specify_actions_checkbox = tk.Checkbutton(action_window, text=\"Specify Actions\", variable=specify_actions_var, command=lambda: on_checkbox_selected(specify_actions_var))\n",
    "    specify_actions_checkbox.pack(anchor='w')\n",
    "\n",
    "    # --- Number of Actions Section ---\n",
    "    number_of_actions_frame = tk.Frame(action_window)\n",
    "    tk.Label(number_of_actions_frame, text=\"Number of Actions:\").pack(side=tk.LEFT)\n",
    "    num_actions_entry = tk.Entry(number_of_actions_frame)\n",
    "    num_actions_entry.pack(side=tk.LEFT, padx=5)\n",
    "    random_checkbox_var = tk.IntVar()\n",
    "    random_checkbox = tk.Checkbutton(number_of_actions_frame, text=\"Random\", variable=random_checkbox_var)\n",
    "    random_checkbox.pack(side=tk.LEFT)\n",
    "\n",
    "    # --- Specify Actions Section ---\n",
    "    specify_actions_frame = tk.Frame(action_window)\n",
    "\n",
    "    tk.Label(specify_actions_frame, text=\"Search Actions:\").pack()\n",
    "    search_entry_var = tk.StringVar()\n",
    "    search_entry = tk.Entry(specify_actions_frame, textvariable=search_entry_var)\n",
    "    search_entry.pack(pady=5)\n",
    "\n",
    "    search_results_listbox = tk.Listbox(specify_actions_frame, selectmode=tk.MULTIPLE)\n",
    "    search_results_listbox.pack(pady=5)\n",
    "\n",
    "    tk.Label(specify_actions_frame, text=\"Selected Actions:\").pack()\n",
    "    selected_actions_listbox = tk.Listbox(specify_actions_frame)\n",
    "    selected_actions_listbox.pack(pady=5)\n",
    "\n",
    "    # Create model CSV button\n",
    "    create_csv_button = tk.Button(action_window, text=\"Create CSV\", command=on_create_model_csv)\n",
    "    create_csv_button.pack(pady=20)\n",
    "\n",
    "    # Initially display the appropriate frame based on checkbox selection\n",
    "    on_checkbox_selected(all_actions_var)\n",
    "\n",
    "# Function for opening the Settings window\n",
    "def open_settings():\n",
    "    # Close the current window before opening a new one\n",
    "    close_current_window()\n",
    "\n",
    "    # Create a new window for settings\n",
    "    settings_window = tk.Toplevel(root)\n",
    "    settings_window.title(\"Settings\")\n",
    "    settings_window.geometry(\"300x200\")\n",
    "\n",
    "    # Track the newly opened window\n",
    "    global open_window\n",
    "    open_window = settings_window\n",
    "\n",
    "    tk.Label(settings_window, text=\"Settings Window\").pack()\n",
    "\n",
    "# Main window setup\n",
    "root = tk.Tk()\n",
    "root.title(\"Main Window\")\n",
    "root.geometry(\"300x150\")  # Set the size of the main window\n",
    "\n",
    "# Add the \"Run Model\" button (you'll need to implement `interpretation` function if needed)\n",
    "run_model_button = tk.Button(root, text=\"Run Model\", command=lambda: print(\"Run model pressed\"))\n",
    "run_model_button.pack(pady=20)\n",
    "\n",
    "# Add the \"Create Model\" button to open model creation\n",
    "create_model_button = tk.Button(root, text=\"Create Model\", command=create_new_model)\n",
    "create_model_button.pack(pady=20)\n",
    "\n",
    "# Add the \"Settings\" button\n",
    "settings_button = tk.Button(root, text=\"Settings\", command=open_settings)\n",
    "settings_button.pack(pady=10)\n",
    "\n",
    "# Load actions from CSV when the program starts\n",
    "load_actions()\n",
    "\n",
    "# Run the main loop to display the window\n",
    "root.mainloop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs456",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
